{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import keras\n",
    "from os import path\n",
    "from flask import Flask, jsonify, request\n",
    "from keras.models import load_model\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./nakano.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[109, 130, 175],\n",
       "        [112, 133, 178],\n",
       "        [114, 135, 180],\n",
       "        ...,\n",
       "        [108, 124, 167],\n",
       "        [110, 123, 167],\n",
       "        [110, 123, 167]],\n",
       "\n",
       "       [[107, 128, 173],\n",
       "        [109, 130, 175],\n",
       "        [110, 131, 176],\n",
       "        ...,\n",
       "        [108, 124, 167],\n",
       "        [109, 125, 168],\n",
       "        [110, 126, 169]],\n",
       "\n",
       "       [[106, 127, 172],\n",
       "        [106, 127, 172],\n",
       "        [104, 127, 172],\n",
       "        ...,\n",
       "        [108, 124, 167],\n",
       "        [110, 126, 169],\n",
       "        [111, 127, 170]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[130, 136, 147],\n",
       "        [130, 136, 147],\n",
       "        [130, 136, 147],\n",
       "        ...,\n",
       "        [ 12,  10,  10],\n",
       "        [ 13,  11,  11],\n",
       "        [ 14,  12,  12]],\n",
       "\n",
       "       [[130, 139, 149],\n",
       "        [129, 138, 148],\n",
       "        [128, 137, 147],\n",
       "        ...,\n",
       "        [ 11,   9,   9],\n",
       "        [ 12,  10,  10],\n",
       "        [ 12,  10,  10]],\n",
       "\n",
       "       [[130, 139, 148],\n",
       "        [129, 138, 147],\n",
       "        [128, 137, 146],\n",
       "        ...,\n",
       "        [ 11,   9,   9],\n",
       "        [ 10,   8,   8],\n",
       "        [ 10,   8,   8]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_alt.xml\")\n",
    "face_list=cascade.detectMultiScale(img_gray, scaleFactor=1.1, minNeighbors=2,minSize=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(face_list) == 1:\n",
    "    for rect in face_list:\n",
    "        x,y,width,height=rect\n",
    "        img = img[rect[1]:rect[1]+rect[3],rect[0]:rect[0]+rect[2]]\n",
    "        if img.shape[0]<64:\n",
    "            continue\n",
    "        img = cv2.resize(img,(64,64))\n",
    "        img_only_face = img\n",
    "        pilImg = Image.fromarray(np.uint8(img_only_face))\n",
    "        buffered = io.BytesIO()\n",
    "        pilImg.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue())\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        img = np.array(img)\n",
    "        img_array = []\n",
    "        img_array.append(img)\n",
    "        img_input=np.array(img_array)\n",
    "        model = load_model(\"./FaceRecog.h5\")\n",
    "        ans = model.predict(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00642716, 0.5763953 , 0.41586345, 0.00131412]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis= [\"齋藤飛鳥\",\"生田絵梨花\",\"西野七瀬\",\"白石麻衣\"]\n",
    "iter = np.argmax(ans, axis = None, out = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
